# Mini DOAMP 面试高频问答预案

> 按简历 8 条逐条整理，每条包含：可能被问的问题、标准回答、追问应对、代码指向

## 第1条：预警引擎（策略模式）

### Q1：预警引擎为什么要重构？原来的痛点是什么？

**回答：**
原来的预警和事件表是强耦合的，预警逻辑直接写在事件处理代码里，新增一种指标类型需要改动多处代码——Controller 要加分支、Service 要加判断、SQL 要加查询。每次改动都有回归风险。

重构后拆成"指标主表 + 阈值子表"的独立预警引擎，指标定义和阈值配置完全数据驱动，预警逻辑通过策略模式按指标类型路由，新增类型只需要加一个策略实现类并注册到 Map 里，引擎代码零改动。

**追问：怎么注册到 Map 的？**
> 每个策略类用 `@Component` 注解标注，实现 `WarnStrategy` 接口并声明自己处理的 `IndexType`。`WarnEngine` 构造时通过 Spring 注入所有策略实现，自动构建 `Map<IndexType, WarnStrategy>`。

**代码指向：** `mini-doamp-event/strategy/` 目录下 7 个策略类 + `WarnEngine`

### Q2：7种指标类型的查询逻辑有什么区别？

**回答：**
分两大类：
- **直接查询类**（运行类、运营类）：直接查对应指标数据表的最新值，和阈值上下限做比较。区别只是数据来源表不同。
- **分组查询类**（银行、渠道、员工、营业部）：需要按分组字段（如银行名称、渠道名称）做 GROUP BY 查询，每个分组的值都要和阈值逐个对比，可能一次检查产生多条预警记录。
- **自定义SQL类**：用户在指标配置里写 SQL，引擎执行后拿结果对比阈值。这个需要做 SQL 注入防护。

**追问：自定义SQL怎么防注入？**
> 两层防护：第一层是关键字白名单，只允许 SELECT 开头，禁止 DROP/DELETE/UPDATE/INSERT/ALTER/TRUNCATE 等危险关键字；第二层是语法校验，对 SQL 做正则检查确保不包含多语句（分号分隔）和注释符号（`--`、`/*`），防止绕过白名单。用户配置的 SQL 本身是完整查询语句，不涉及外部参数拼接。
>
> **再追问：正则/黑白名单能被绕过吗？有没有更安全的方案？**
> 确实存在绕过风险（比如编码绕过、嵌套注释等）。更安全的方案有两种：一是只允许预置 SQL 模板，用户只能选择模板并填参数，不能自由编写 SQL；二是引入 SQL AST 解析器（如 JSqlParser），将 SQL 解析成语法树后校验只包含 SELECT 语句且不含子查询中的写操作。我们当前场景是内部运维人员配置，风险可控，所以用了白名单方案。如果面向外部用户，会改用预置模板方案。

### Q3：如果让你再加一种指标类型，需要改哪些代码？

**回答：**
只需要三步：
1. 在 `IndexType` 枚举中加一个值
2. 新建一个策略类实现 `WarnStrategy` 接口，加 `@Component` 注解
3. 如果数据来源是新表，加对应的 Mapper

引擎代码、Controller、其他策略类都不需要改动。这就是策略模式的扩展性优势——符合开闭原则。

## 第2条：消息推送（RabbitMQ）

### Q1：为什么用 Topic Exchange 而不是 Direct 或 Fanout？

**回答：**
我们的路由需求是按通知方式（短信/邮件/企微）分发到不同队列。Direct Exchange 需要精确匹配 routing key，虽然也能实现，但 Topic Exchange 支持通配符匹配，扩展性更好。比如将来要加一个"全部通知"的消费者，用 `warn.*` 就能订阅所有队列，Direct 做不到。Fanout 是广播模式，所有队列都收到同一条消息，不符合我们按类型分发的需求。

**追问：routing key 怎么设计的？**
> `warn.sms`、`warn.email`、`warn.wxwork`，队列分别绑定对应的 key。生产者根据预警规则配置的通知方式，拆分成多条消息分别发送。

### Q2：幂等消费怎么实现的？

**回答：**
每条消息生成时分配一个 UUID 作为 msg_id，写入消息流水表。消费者收到消息后，先用 `SISMEMBER` 检查 msg_id 是否已存在于 Redis SET 中：
- 存在 → 说明已消费过，直接 ACK 跳过
- 不存在 → 执行业务逻辑，成功后 `SADD` 写入 SET，再 ACK

**追问：Redis SET 会不会无限增长？**
> 会设置过期时间，比如 24 小时。因为消息重复投递一般发生在短时间内（MQ 重试、网络抖动），24 小时后的消息不可能再重复投递。

**追问：如果 SADD 成功但业务执行失败怎么办？**
> 顺序是先执行业务逻辑，成功后再 SADD。如果业务失败，不写 SET，消息会被 NACK 进入死信队列等待重试。

### Q3：死信队列和重试机制怎么配合的？

**回答：**
消费者处理失败时 NACK 并且不 requeue，消息自动进入死信队列（通过 DLX 死信交换机路由）。然后有一个定时任务每隔一段时间扫描消息流水表中 status=FAILED 的记录：
- retry_count < 3：重新发送到原队列，retry_count +1，状态改为 RETRYING
- retry_count >= 3：状态标记为 ALARM，不再重试，等人工处理

**追问：为什么不用 RabbitMQ 自带的重试（TTL + DLX 回流）？**
> 自带重试不好控制重试间隔和次数，而且重试状态无法持久化到数据库。用定时任务扫描的方式，每次重试都有流水记录，方便排查问题，也方便在管理界面上手动触发重试。

**代码指向：** `mini-doamp-event/mq/` 目录下 producer + consumer + RabbitMQ 配置类

## 第3条：Redis 缓存

### Q1：Cache Aside 模式的读写流程是什么？

**回答：**
读流程：先查 Redis 缓存，命中直接返回；未命中则查 DB，查到数据后回填缓存并返回，查不到则缓存空值（短 TTL）防穿透。

写流程：先更新 DB，再删除缓存。不是先删缓存再更新 DB，因为那样在并发场景下会有脏数据问题——线程A删缓存后还没更新DB，线程B读到旧数据回填了缓存。

**追问：为什么不用 Read/Write Through 或 Write Behind？**
> Read/Write Through 需要缓存层代理所有数据库操作，实现复杂度高。Write Behind 是异步写DB，有数据丢失风险。Cache Aside 是最简单可靠的方案，适合我们的场景。

### Q2：延迟双删是怎么回事？为什么要删两次？

**回答：**
场景：线程A更新完DB并删了缓存，但在删缓存前的瞬间，线程B刚好读到旧缓存miss后查DB拿到旧数据并回填了缓存。结果缓存里是旧数据。

延迟双删的流程：更新DB → 删缓存 → 延迟500ms → 再删一次缓存。第一次删是标准 Cache Aside 的写路径，第二次延迟删是为了清除这个时间窗口内可能被并发读回填的旧数据。

**追问：500ms 怎么定的？**
> 根据业务读请求的平均耗时来定。我们的读请求一般在 100-200ms 内完成，500ms 留了足够余量，确保并发读请求已经完成回填。

### Q3：缓存雪崩和缓存穿透分别怎么防？

**回答：**
缓存雪崩：大量 key 同时过期，请求全部打到 DB。解决方案是给热点数据的 TTL 加随机偏移，比如基础 30 分钟 ± 5 分钟的随机值，让过期时间分散开。

缓存穿透：查询一个不存在的数据，缓存永远 miss，每次都打 DB。解决方案是查询结果为空时也缓存一个空值（null 标记），设置短 TTL（5 分钟），避免反复查 DB。

**追问：布隆过滤器为什么没用？**
> 布隆过滤器适合数据量大且查询 key 可枚举的场景。我们的字典和指标数据量不大，空值缓存就够了，引入布隆过滤器反而增加复杂度。

**代码指向：** `mini-doamp-doamp/service/` 下 CacheService、DictCacheService、IndexCacheService

## 第4条：定时调度（ShedLock 动态锁）

### Q1：ShedLock 动态锁名是怎么回事？解决了什么问题？

**回答：**
线上遇到过一个问题：不同任务模板配置了相同的调度周期（比如每天9点），但 ShedLock 的锁名称是写死的（比如都叫 `warn_check`），导致第一个模板拿到锁执行后，第二个模板发现锁已被占用就跳过了。

解决方案是动态生成锁名称，按任务类型区分粒度：预警检查用 `warn_check_${ruleId}`（如 `warn_check_101`），SOP 任务生成用 `sop_generate_${templateId}`。这样不同规则/模板各自持有独立的锁，同一周期内可以并行执行。

**追问：ShedLock 的锁是怎么实现的？**
> 基于数据库的乐观锁。shedlock 表有 name、lock_until、locked_at、locked_by 四个字段。获取锁时用 INSERT 或 UPDATE（WHERE lock_until <= now），如果成功就拿到锁，失败就跳过。锁到期后自动释放。

### Q2：XXL-Job 和 ShedLock 各自负责什么？

**回答：**
XXL-Job 负责调度触发——什么时候执行、执行哪个 Handler、失败重试策略、执行日志等。ShedLock 负责防重复执行——多个实例同时收到调度信号时，只有一个能拿到锁真正执行。

两者配合：XXL-Job 触发 → Handler 方法上加 `@SchedulerLock` → ShedLock 竞争锁 → 拿到锁的实例执行业务逻辑。

**代码指向：** `mini-doamp-sop/` 下定时任务类 + ShedLock 配置

## 第5条：多库适配（Adapter 工厂）

### Q1：多数据库适配是怎么做的？

**回答：**
三层设计：
1. **识别层**：MyBatis 的 `databaseIdProvider` 自动识别当前连接的数据库类型，返回 `mysql` 或 `h2` 等标识
2. **抽象层**：定义 `DatabaseAdapter` 接口，封装数据库方言差异方法（日期格式化、分页语法、字符串聚合等）
3. **工厂层**：`DatabaseAdapterFactory` 根据 databaseId 返回对应的 Adapter 实现（MysqlAdapter 或 H2Adapter）

Mapper XML 中也可以用 `databaseId` 属性写差异化 SQL，MyBatis 会自动选择匹配当前数据库的语句。

**追问：举个具体的方言差异例子？**
> 日期格式化：MySQL 用 `DATE_FORMAT(col, '%Y-%m-%d')`，H2 用 `FORMATDATETIME(col, 'yyyy-MM-dd')`。分页语法：MySQL 是 `LIMIT offset, size`，H2 是 `LIMIT size OFFSET offset`，参数顺序不同。

**追问：为什么不直接用 JPA 的方言机制？**
> 我们用的是 MyBatis，没有 JPA 的 Dialect 抽象。MyBatis 的 databaseIdProvider 是官方推荐的多库适配方案，配合自定义 Adapter 工厂，既灵活又不依赖额外框架。

**代码指向：** `mini-doamp-core/adapter/` 下 DatabaseAdapter 接口 + 工厂 + 实现类

## 第6条：慢查询优化（口述项）

### Q1：慢查询优化的思路是什么？

**回答：**
四步走：
1. **定位慢SQL**：开启 MySQL 慢查询日志（slow_query_log），设置阈值（如 1s），收集慢 SQL
2. **EXPLAIN 分析**：看执行计划，重点关注 type（是否全表扫描）、key（是否走索引）、rows（扫描行数）、Extra（是否 Using filesort/Using temporary）
3. **优化索引**：根据 WHERE、ORDER BY、GROUP BY 的字段组合添加联合索引，注意最左前缀原则
4. **验证效果**：优化后再次 EXPLAIN 确认走了索引，对比执行时间

**追问：你遇到过什么具体的慢查询案例？**
> 驾驶舱报表查询，原来 3s+。EXPLAIN 发现 WHERE 条件里用了 `DATE_FORMAT(create_time, '%Y-%m')` 做过滤，导致索引失效（函数调用破坏了索引的 B+ 树结构）。改成范围查询 `create_time BETWEEN '2024-01-01' AND '2024-01-31'` 后走了索引，再加上覆盖索引（把 SELECT 的字段都放进联合索引），最终降到 200ms 以内。

**追问：什么是覆盖索引？**
> 查询需要的所有字段都在索引中，不需要回表查聚簇索引。比如 `SELECT user_id, amount FROM orders WHERE date = '2024-01'`，如果有联合索引 `(date, user_id, amount)`，整个查询只需要扫描索引，Extra 会显示 `Using index`。

## 第7条：SOP 工作流（状态机）

### Q1：状态机是怎么设计的？

**回答：**
用枚举定义所有合法状态，用状态转换矩阵定义哪些状态之间可以转换：

```
CREATED        → PENDING_ASSIGN
PENDING_ASSIGN → EXECUTING
EXECUTING      → APPROVING, TERMINATED
APPROVING      → COMPLETED, REJECTED, EXECUTING（回退）
REJECTED       → EXECUTING（重新执行）
```

每次状态变更前先查转换矩阵校验合法性，非法转换直接抛异常。这样避免了硬编码 if-else 判断状态，新增状态只需要在矩阵里加一行。

### Q2：WorkflowEngine.advance() 的核心流程是什么？

**回答：**
`advance(taskExecId, action, params)` 是整个引擎的核心入口，流程如下：
1. 根据 taskExecId 查当前执行记录，拿到当前节点和任务状态
2. 校验状态转换合法性（查转换矩阵）
3. 根据节点类型路由到对应 Handler（策略模式）：
   - 处理节点 → 记录执行结果
   - 审批节点 → 记录审批意见（通过/驳回）
   - 抄送节点 → 发 RabbitMQ 通知
   - 分支节点 → 评估条件表达式选择分支
4. 查找下一个节点并推进（如果是结束节点则关闭任务）
5. 写入操作流水表（操作人、时间、动作类型、备注）
6. 触发消息通知（发到 RabbitMQ，复用消息推送模块）

### Q3：回退到任意节点是怎么实现的？

**回答：**
维护一个节点执行栈（按执行顺序记录已完成的节点）。回退时：
1. 校验目标节点必须是已完成的节点（不能回退到未执行过的节点）
2. 从栈顶开始，将中间节点的执行记录状态标记为 ROLLED_BACK（不物理删除，保留审计痕迹）
3. 将任务状态回退到目标节点对应的状态
4. 为目标节点重新创建执行记录，分配执行人
5. 写入操作流水表，记录回退动作

**追问：回退时中间节点的审批记录怎么处理？**
> 不物理删除，而是将 TaskExec 记录的 status 标记为 ROLLED_BACK，保留审计痕迹。新的执行记录会重新创建，这样操作流水表能完整追溯整个过程。

**代码指向：** `mini-doamp-sop/engine/` 下 WorkflowEngine + NodeHandler 策略类

## 第8条：gRPC 通信（口述项）

### Q1：gRPC 和 REST 有什么区别？为什么用 gRPC？

**回答：**
| 维度 | gRPC | REST |
|------|------|------|
| 协议 | HTTP/2 | HTTP/1.1 |
| 序列化 | Protobuf（二进制） | JSON（文本） |
| 性能 | 高（体积小、解析快） | 一般 |
| 流式传输 | 支持双向流 | 不支持 |
| 服务契约 | Proto 文件强约束 | Swagger 弱约束 |

我们在微服务内部通信用 gRPC，因为调用频率高、对延迟敏感。对外暴露的接口还是用 REST，方便前端调用。

### Q2：Proto 文件是什么？TLS 双向认证怎么做的？

**回答：**
Proto 文件是 gRPC 的服务契约定义，用 Protocol Buffers 语法描述服务接口和消息结构。编译后自动生成客户端和服务端的 Stub 代码，保证双方接口一致。

TLS 双向认证：不仅客户端验证服务端证书（单向 TLS），服务端也要验证客户端证书。配置时需要：
- 服务端：配置自己的证书 + 私钥 + CA 证书（用于验证客户端）
- 客户端：配置自己的证书 + 私钥 + CA 证书（用于验证服务端）

这样可以防止未授权的服务调用内部接口。

### Q3：Zookeeper 在 gRPC 中起什么作用？

**回答：**
Zookeeper 做服务注册与发现。gRPC 服务启动时把自己的地址（IP:Port）注册到 ZK 的临时节点上，客户端通过 ZK 获取可用的服务实例列表，实现负载均衡。

服务下线时临时节点自动删除（基于 ZK 的会话机制），客户端通过 Watcher 监听节点变化，实时感知服务上下线。

**追问：为什么不用 Nacos？**
> 原项目技术栈已经有 ZK（其他组件也在用），没必要再引入 Nacos。ZK 的 CP 特性（强一致性）也更适合金融场景对服务发现准确性的要求。

## 通用高频追问

### Q：项目中用了哪些设计模式？

**回答：**
- **策略模式**：预警引擎（7种指标类型路由）、工作流节点处理（4种节点类型各有 Handler）
- **工厂模式**：数据库适配器工厂（根据数据库类型返回对应 Adapter）
- **状态机模式**：SOP 任务生命周期管理（枚举状态 + 转换矩阵）
- **观察者模式**：RabbitMQ 消息发布/订阅（预警触发 → 消息消费）
- **模板方法模式**：CacheService 中的缓存读写模板（统一处理缓存 miss、空值、TTL）

### Q：项目中遇到过什么线上问题？怎么排查的？

**回答：**
最典型的是 ShedLock 锁名冲突问题。现象是不同任务模板在同一调度周期只有一个能执行，其他都被跳过。

排查过程：
1. 看日志发现被跳过的任务打了 ShedLock 的 "Locked" 日志
2. 查 shedlock 表发现锁名都是 `warn_check`，lock_until 还没过期
3. 定位到锁名是硬编码的，不同模板共用同一个锁
4. 改为动态生成锁名 `warn_check_${ruleId}`，问题解决

### Q：如果让你重新设计这个系统，你会做什么改进？

**回答：**
1. **预警引擎**：加入规则引擎（如 Drools），支持更复杂的组合条件判断，不只是简单的阈值对比
2. **消息推送**：引入消息模板引擎（如 FreeMarker），让消息内容可配置化
3. **工作流**：支持并行节点（会签/或签），目前只支持串行流程
4. **缓存**：引入多级缓存（本地缓存 + Redis），减少 Redis 网络开销
5. **监控**：接入 Prometheus + Grafana，对预警引擎的执行耗时、消息投递成功率等做可视化监控

### Q：简历提到"审批"，具体是怎么实现的？

**回答：**
审批是作为流程节点类型（APPROVE）实现的，不是独立的子流程。审批节点支持三种操作：
- **通过**：流程推进到下一个节点
- **驳回**：任务状态变为 REJECTED，可以重新发起执行
- **回退**：支持回退到任意已完成的节点，中间节点的执行记录标记为 ROLLED_BACK

审批节点和处理节点的区别在于：处理节点只需要提交执行结果，审批节点需要做通过/驳回的决策，并且审批意见会记录到执行记录和操作流水表中。

**追问：为什么不用 Activiti 的子流程？**
> 我们的审批场景相对简单（单人审批、通过/驳回），不需要 Activiti 那种复杂的子流程嵌套。用节点类型 + 策略模式就能满足需求，代码更可控，回退逻辑也更灵活。
